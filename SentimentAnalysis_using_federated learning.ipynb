{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T20:10:23.866884Z",
     "iopub.status.busy": "2025-04-13T20:10:23.866580Z",
     "iopub.status.idle": "2025-04-13T22:38:45.155288Z",
     "shell.execute_reply": "2025-04-13T22:38:45.154324Z",
     "shell.execute_reply.started": "2025-04-13T20:10:23.866859Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=3, no round_timeout\n",
      "2025-04-13 20:10:51,956\tINFO worker.py:1852 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'node:172.19.2.2': 1.0, 'node:__internal_head__': 1.0, 'accelerator_type:P100': 1.0, 'CPU': 4.0, 'memory': 20105474458.0, 'object_store_memory': 8616631910.0, 'GPU': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      No `client_resources` specified. Using minimal resources for clients.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 4 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[36m(pid=2634)\u001b[0m 2025-04-13 20:10:54.721742: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=2634)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(pid=2634)\u001b[0m E0000 00:00:1744575054.762423    2634 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=2634)\u001b[0m E0000 00:00:1744575054.775416    2634 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m             This is a deprecated feature. It will be removed\n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m             entirely in future versions of Flower.\n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m         \n",
      "\u001b[36m(pid=2637)\u001b[0m 2025-04-13 20:10:54.786316: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=2636)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=2636)\u001b[0m E0000 00:00:1744575054.887820    2636 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=2636)\u001b[0m E0000 00:00:1744575054.900509    2636 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m             This is a deprecated feature. It will be removed\n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m             entirely in future versions of Flower.\n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=2635)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
      "\u001b[36m(ClientAppActor pid=2635)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2635)\u001b[0m             This is a deprecated feature. It will be removed\n",
      "\u001b[36m(ClientAppActor pid=2635)\u001b[0m             entirely in future versions of Flower.\n",
      "\u001b[36m(ClientAppActor pid=2635)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=2634)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2634)\u001b[0m         \n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[36m(ClientAppActor pid=2634)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2634)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=2634)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2634)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2634)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=2635)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2635)\u001b[0m         \n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2634)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2634)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=2635)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2635)\u001b[0m         \n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[36m(ClientAppActor pid=2635)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2635)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=2635)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2635)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2635)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=2634)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2634)\u001b[0m         \n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2634)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2634)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=2635)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2635)\u001b[0m         \n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[36m(ClientAppActor pid=2635)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2635)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=2635)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2635)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2635)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2634)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2634)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2637)\u001b[0m         \n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 3 round(s) in 8850.51s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.539802711699009\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.4115874604153633\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.4004724809324741\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 72.205), (2, 81.02424999999998), (3, 81.57075)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Global Accuracy After Each Round:\n",
      "Round 1: 72.20%\n",
      "Round 2: 81.02%\n",
      "Round 3: 81.57%\n",
      "\n",
      "✅ Final Global Accuracy: 81.57%\n"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "#  SETUP --- global accuracy witn round names..final correct version\n",
    "# ======================\n",
    "!pip install flwr --quiet\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import flwr as fl\n",
    "\n",
    "set_seed = lambda seed=42: [torch.manual_seed(seed), np.random.seed(seed), random.seed(seed)]\n",
    "set_seed()\n",
    "\n",
    "# Paths\n",
    "DATASET_PATH = \"/kaggle/input/dataset-sentiment140/\"\n",
    "GLOVE_PATH = os.path.join(DATASET_PATH, \"glove.6B.100d.txt\")\n",
    "\n",
    "# Global config\n",
    "MAX_WORDS = 3000\n",
    "SEQ_LEN = 100\n",
    "EMBED_DIM = 100\n",
    "\n",
    "# Tokenizer and encoder\n",
    "global_tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
    "global_label_encoder = LabelEncoder()\n",
    "fitted_tokenizer = False\n",
    "fitted_label_encoder = False\n",
    "\n",
    "# ======================\n",
    "#  Load Client Data\n",
    "# ======================\n",
    "def load_client_data(path):\n",
    "    global fitted_tokenizer\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "    \n",
    "    texts = df['text'].astype(str).tolist()\n",
    "    labels = df['target'].values  # ✅ direct numeric labels (0 or 1)\n",
    "\n",
    "    if not fitted_tokenizer:\n",
    "        global_tokenizer.fit_on_texts(texts)\n",
    "        fitted_tokenizer = True\n",
    "\n",
    "    sequences = global_tokenizer.texts_to_sequences(texts)\n",
    "    padded = pad_sequences(sequences, maxlen=SEQ_LEN, padding='post')\n",
    "    X = torch.tensor(padded, dtype=torch.long)\n",
    "    y = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    return DataLoader(TensorDataset(X, y), batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "def load_test_data():\n",
    "    df = pd.read_csv(os.path.join(DATASET_PATH, \"test_data.csv\"))\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "    texts = df[\"text\"].astype(str).tolist()\n",
    "    labels = df[\"target\"].values  # ✅ direct numeric labels\n",
    "\n",
    "    sequences = global_tokenizer.texts_to_sequences(texts)\n",
    "    padded = pad_sequences(sequences, maxlen=SEQ_LEN, padding='post')\n",
    "    X = torch.tensor(padded, dtype=torch.long)\n",
    "    y = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    return DataLoader(TensorDataset(X, y), batch_size=32)\n",
    "\n",
    "# ======================\n",
    "#  Load GloVe\n",
    "# ======================\n",
    "def load_glove_embeddings():\n",
    "    embeddings_index = {}\n",
    "    with open(GLOVE_PATH, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coeffs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coeffs\n",
    "\n",
    "    vocab_size = min(MAX_WORDS, len(global_tokenizer.word_index) + 1)\n",
    "    embedding_matrix = np.zeros((vocab_size, EMBED_DIM))\n",
    "    for word, i in global_tokenizer.word_index.items():\n",
    "        if i < MAX_WORDS:\n",
    "            vec = embeddings_index.get(word)\n",
    "            if vec is not None:\n",
    "                embedding_matrix[i] = vec\n",
    "    return torch.tensor(embedding_matrix, dtype=torch.float)\n",
    "\n",
    "# ======================\n",
    "#  Model with Attention\n",
    "# ======================\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_dim * 2, 1)\n",
    "    def forward(self, x):\n",
    "        weights = torch.softmax(self.attn(x), dim=1)\n",
    "        return torch.sum(weights * x, dim=1)\n",
    "\n",
    "class CNN_BiGRU_Attn(nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        vocab_size, embed_dim = embedding_matrix.shape\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
    "        self.conv = nn.Conv1d(embed_dim, embed_dim, kernel_size=3, padding=1)\n",
    "        self.bigru = nn.GRU(embed_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.attn = Attention(hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = torch.relu(self.conv(x))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        gru_out, _ = self.bigru(x)\n",
    "        x = self.attn(gru_out)\n",
    "        return self.fc(self.dropout(x))\n",
    "\n",
    "# ======================\n",
    "#  Flower Client\n",
    "# ======================\n",
    "class SentimentClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, trainloader):\n",
    "        self.model = model\n",
    "        self.trainloader = trainloader\n",
    "        self.testloader = load_test_data()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    def get_parameters(self, config): return [val.cpu().numpy() for val in self.model.state_dict().values()]\n",
    "    def set_parameters(self, parameters):\n",
    "        state_dict = self.model.state_dict()\n",
    "        for k, v in zip(state_dict.keys(), parameters):\n",
    "            state_dict[k] = torch.tensor(v)\n",
    "        self.model.load_state_dict(state_dict)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        self.model.train()\n",
    "        for x, y in self.trainloader:\n",
    "            self.optimizer.zero_grad()\n",
    "            out = self.model(x)\n",
    "            loss = self.criterion(out, y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        return self.get_parameters({}), len(self.trainloader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        self.model.eval()\n",
    "        total, correct, total_loss = 0, 0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y in self.testloader:\n",
    "                out = self.model(x)\n",
    "                loss = self.criterion(out, y)\n",
    "                total_loss += loss.item()\n",
    "                total += y.size(0)\n",
    "                correct += (out.argmax(1) == y).sum().item()\n",
    "        acc = 100 * correct / total\n",
    "        avg_loss = total_loss / len(self.testloader)\n",
    "        #print(f\"🧪 Global Evaluation - Accuracy: {acc:.2f}%, Loss: {avg_loss:.4f}\")\n",
    "        return avg_loss, total, {\"accuracy\": acc}\n",
    "\n",
    "# ======================\n",
    "#  Run FL Simulation\n",
    "# ======================\n",
    "# ======================\n",
    "#  Run FL Simulation with 3 Rounds\n",
    "# ======================\n",
    "from flwr.common import Context  # Make sure this import is included\n",
    "\n",
    "def client_fn(cid: str):\n",
    "    path = os.path.join(DATASET_PATH, f\"client_{int(cid)+1}_data.csv\")\n",
    "    trainloader = load_client_data(path)\n",
    "    model = CNN_BiGRU_Attn(embedding_matrix, hidden_dim=128, output_dim=2)\n",
    "    client = SentimentClient(model, trainloader)\n",
    "    return client.to_client()  # Works with Flower 1.x\n",
    "\n",
    "\n",
    "# Tokenizer fitting (required before loading GloVe)\n",
    "_ = load_client_data(os.path.join(DATASET_PATH, \"client_1_data.csv\"))\n",
    "embedding_matrix = load_glove_embeddings()\n",
    "\n",
    "#  Set rounds to 3\n",
    "def weighted_average(metrics):\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    total_examples = sum(num_examples for num_examples, _ in metrics)\n",
    "    return {\"accuracy\": sum(accuracies) / total_examples}\n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,\n",
    ")\n",
    "\n",
    "# Run simulation and capture history\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=3,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),\n",
    "    strategy=strategy,\n",
    ")\n",
    "\n",
    "#  Print global accuracy after each round\n",
    "print(\"\\n📊 Global Accuracy After Each Round:\")\n",
    "for round_num, acc in history.metrics_distributed[\"accuracy\"]:\n",
    "    print(f\"Round {round_num}: {acc:.2f}%\")\n",
    "\n",
    "#  Final accuracy\n",
    "final_acc = history.metrics_distributed[\"accuracy\"][-1][1]\n",
    "print(f\"\\n✅ Final Global Accuracy: {final_acc:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7125912,
     "sourceId": 11380834,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7125979,
     "sourceId": 11380918,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7126287,
     "sourceId": 11381295,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
