{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T06:07:08.406689Z",
     "iopub.status.busy": "2025-04-25T06:07:08.406060Z",
     "iopub.status.idle": "2025-04-25T06:50:33.356605Z",
     "shell.execute_reply": "2025-04-25T06:50:33.355533Z",
     "shell.execute_reply.started": "2025-04-25T06:07:08.406659Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n",
      "2025-04-25 06:07:27,085\tINFO worker.py:1852 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'node:172.19.2.2': 1.0, 'node:__internal_head__': 1.0, 'accelerator_type:P100': 1.0, 'CPU': 4.0, 'object_store_memory': 8839442841.0, 'memory': 20625366631.0, 'GPU': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      No `client_resources` specified. Using minimal resources for clients.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 4 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[36m(pid=590)\u001b[0m 2025-04-25 06:07:29.435760: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=589)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(pid=589)\u001b[0m E0000 00:00:1745561249.479051     589 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=589)\u001b[0m E0000 00:00:1745561249.491464     589 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m             This is a deprecated feature. It will be removed\n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m             entirely in future versions of Flower.\n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m         \n",
      "\u001b[36m(pid=587)\u001b[0m 2025-04-25 06:07:29.505351: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=587)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=587)\u001b[0m E0000 00:00:1745561249.550757     587 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=587)\u001b[0m E0000 00:00:1745561249.562767     587 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m             This is a deprecated feature. It will be removed\n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m             entirely in future versions of Flower.\n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m             This is a deprecated feature. It will be removed\n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m             entirely in future versions of Flower.\n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m             This is a deprecated feature. It will be removed\n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m             entirely in future versions of Flower.\n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m         \n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m             This is a deprecated feature. It will be removed\n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m             entirely in future versions of Flower.\n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m             This is a deprecated feature. It will be removed\n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m             entirely in future versions of Flower.\n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m         \n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m         \n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m         \n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m         \n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m         \n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m         \n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m         \n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m         \n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=588)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=590)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=587)\u001b[0m         \n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 2574.35s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.4763615850284287\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.43414644102210104\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.42885678976610764\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.42376300225364655\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.4206963051757494\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 77.83857142857143),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, 79.68428571428574),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, 80.04714285714286),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, 80.33571428571429),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, 80.41285714285715)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'f1_score': [(1, 77.7643501188478),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, 79.68203922474869),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, 80.04563036671821),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, 80.33112760877962),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, 80.4028781957711)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'precision': [(1, 78.23281170146444),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (2, 79.6945290486099),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (3, 80.05918502628884),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (4, 80.36896396497579),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (5, 80.48208194548667)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'recall': [(1, 77.83857142857143),\n",
      "\u001b[92mINFO \u001b[0m:      \t            (2, 79.68428571428574),\n",
      "\u001b[92mINFO \u001b[0m:      \t            (3, 80.04714285714286),\n",
      "\u001b[92mINFO \u001b[0m:      \t            (4, 80.33571428571429),\n",
      "\u001b[92mINFO \u001b[0m:      \t            (5, 80.41285714285712)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Global Metrics After Each Round:\n",
      "Round 1 => Accuracy: 77.84%, Precision: 78.23%, Recall: 77.84%, F1-score: 77.76%\n",
      "Round 2 => Accuracy: 79.68%, Precision: 79.69%, Recall: 79.68%, F1-score: 79.68%\n",
      "Round 3 => Accuracy: 80.05%, Precision: 80.06%, Recall: 80.05%, F1-score: 80.05%\n",
      "Round 4 => Accuracy: 80.34%, Precision: 80.37%, Recall: 80.34%, F1-score: 80.33%\n",
      "Round 5 => Accuracy: 80.41%, Precision: 80.48%, Recall: 80.41%, F1-score: 80.40%\n",
      "\n",
      "Final Metrics â€” Accuracy: 80.41%, Precision: 80.48%, Recall: 80.41%, F1-score: 80.40%\n"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "# ðŸš€ SETUP --- global accuracy with precision, recall, and F1-score \n",
    "# ======================\n",
    "!pip install flwr --quiet\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import flwr as fl\n",
    "\n",
    "set_seed = lambda seed=42: [torch.manual_seed(seed), np.random.seed(seed), random.seed(seed)]\n",
    "set_seed()\n",
    "\n",
    "# Paths\n",
    "DATASET_PATH = \"/kaggle/input/data70k/\"\n",
    "GLOVE_PATH = os.path.join(DATASET_PATH, \"glove.6B.100d.txt\")\n",
    "\n",
    "# Global config\n",
    "MAX_WORDS = 3000\n",
    "SEQ_LEN = 100\n",
    "EMBED_DIM = 100\n",
    "\n",
    "# Tokenizer and encoder\n",
    "global_tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
    "global_label_encoder = LabelEncoder()\n",
    "fitted_tokenizer = False\n",
    "fitted_label_encoder = False\n",
    "\n",
    "# ======================\n",
    "# ðŸ“… Load Client Data\n",
    "# ======================\n",
    "def load_client_data(path):\n",
    "    global fitted_tokenizer\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "    texts = df['text'].astype(str).tolist()\n",
    "    labels = df['target'].values\n",
    "\n",
    "    if not fitted_tokenizer:\n",
    "        global_tokenizer.fit_on_texts(texts)\n",
    "        fitted_tokenizer = True\n",
    "\n",
    "    sequences = global_tokenizer.texts_to_sequences(texts)\n",
    "    padded = pad_sequences(sequences, maxlen=SEQ_LEN, padding='post')\n",
    "    X = torch.tensor(padded, dtype=torch.long)\n",
    "    y = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    return DataLoader(TensorDataset(X, y), batch_size=32, shuffle=True)\n",
    "\n",
    "def load_test_data():\n",
    "    df = pd.read_csv(os.path.join(DATASET_PATH, \"test_data.csv\"))\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "    texts = df[\"text\"].astype(str).tolist()\n",
    "    labels = df[\"target\"].values\n",
    "\n",
    "    sequences = global_tokenizer.texts_to_sequences(texts)\n",
    "    padded = pad_sequences(sequences, maxlen=SEQ_LEN, padding='post')\n",
    "    X = torch.tensor(padded, dtype=torch.long)\n",
    "    y = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    return DataLoader(TensorDataset(X, y), batch_size=32)\n",
    "\n",
    "# ======================\n",
    "# ðŸ”  Load GloVe\n",
    "# ======================\n",
    "def load_glove_embeddings():\n",
    "    embeddings_index = {}\n",
    "    with open(GLOVE_PATH, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coeffs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coeffs\n",
    "\n",
    "    vocab_size = min(MAX_WORDS, len(global_tokenizer.word_index) + 1)\n",
    "    embedding_matrix = np.zeros((vocab_size, EMBED_DIM))\n",
    "    for word, i in global_tokenizer.word_index.items():\n",
    "        if i < MAX_WORDS:\n",
    "            vec = embeddings_index.get(word)\n",
    "            if vec is not None:\n",
    "                embedding_matrix[i] = vec\n",
    "    return torch.tensor(embedding_matrix, dtype=torch.float)\n",
    "\n",
    "# ======================\n",
    "# ðŸ§ Model with Attention\n",
    "# ======================\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_dim * 2, 1)\n",
    "    def forward(self, x):\n",
    "        weights = torch.softmax(self.attn(x), dim=1)\n",
    "        return torch.sum(weights * x, dim=1)\n",
    "\n",
    "class CNN_BiGRU_Attn(nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        vocab_size, embed_dim = embedding_matrix.shape\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
    "        self.conv = nn.Conv1d(embed_dim, embed_dim, kernel_size=3, padding=1)\n",
    "        self.bigru = nn.GRU(embed_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.attn = Attention(hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = torch.relu(self.conv(x))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        gru_out, _ = self.bigru(x)\n",
    "        x = self.attn(gru_out)\n",
    "        return self.fc(self.dropout(x))\n",
    "\n",
    "# ======================\n",
    "# ðŸŒ¸ Flower Client\n",
    "# ======================\n",
    "class SentimentClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, trainloader):\n",
    "        self.model = model\n",
    "        self.trainloader = trainloader\n",
    "        self.testloader = load_test_data()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    def get_parameters(self, config): return [val.cpu().numpy() for val in self.model.state_dict().values()]\n",
    "    def set_parameters(self, parameters):\n",
    "        state_dict = self.model.state_dict()\n",
    "        for k, v in zip(state_dict.keys(), parameters):\n",
    "            state_dict[k] = torch.tensor(v)\n",
    "        self.model.load_state_dict(state_dict)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        self.model.train()\n",
    "        for x, y in self.trainloader:\n",
    "            self.optimizer.zero_grad()\n",
    "            out = self.model(x)\n",
    "            loss = self.criterion(out, y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        return self.get_parameters({}), len(self.trainloader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        self.model.eval()\n",
    "        total, correct, total_loss = 0, 0, 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in self.testloader:\n",
    "                out = self.model(x)\n",
    "                loss = self.criterion(out, y)\n",
    "                total_loss += loss.item()\n",
    "                total += y.size(0)\n",
    "                correct += (out.argmax(1) == y).sum().item()\n",
    "                all_preds.extend(out.argmax(1).cpu().numpy())\n",
    "                all_labels.extend(y.cpu().numpy())\n",
    "        acc = 100 * correct / total\n",
    "        avg_loss = total_loss / len(self.testloader)\n",
    "        precision = precision_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
    "        recall = recall_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
    "        f1 = f1_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
    "        return avg_loss, total, {\n",
    "            \"accuracy\": acc,\n",
    "            \"precision\": precision * 100,\n",
    "            \"recall\": recall * 100,\n",
    "            \"f1_score\": f1 * 100\n",
    "        }\n",
    "\n",
    "# ======================\n",
    "# ðŸš€ Run FL Simulation\n",
    "# ======================\n",
    "from flwr.common import Context\n",
    "\n",
    "def client_fn(cid: str):\n",
    "    path = os.path.join(DATASET_PATH, f\"client_{int(cid)+1}_data.csv\")\n",
    "    trainloader = load_client_data(path)\n",
    "    model = CNN_BiGRU_Attn(embedding_matrix, hidden_dim=128, output_dim=2)\n",
    "    client = SentimentClient(model, trainloader)\n",
    "    return client.to_client()\n",
    "\n",
    "_ = load_client_data(os.path.join(DATASET_PATH, \"client_1_data.csv\"))\n",
    "embedding_matrix = load_glove_embeddings()\n",
    "\n",
    "def weighted_average(metrics):\n",
    "    total_examples = sum(num_examples for num_examples, _ in metrics)\n",
    "    def weighted(key):\n",
    "        return sum(num_examples * m[key] for num_examples, m in metrics) / total_examples\n",
    "    return {\n",
    "        \"accuracy\": weighted(\"accuracy\"),\n",
    "        \"precision\": weighted(\"precision\"),\n",
    "        \"recall\": weighted(\"recall\"),\n",
    "        \"f1_score\": weighted(\"f1_score\")\n",
    "    }\n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,\n",
    ")\n",
    "\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=3,\n",
    "    config=fl.server.ServerConfig(num_rounds=5),\n",
    "    strategy=strategy,\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ“Š Global Metrics After Each Round:\")\n",
    "for round_num, acc in history.metrics_distributed[\"accuracy\"]:\n",
    "    prec = history.metrics_distributed[\"precision\"][round_num - 1][1]\n",
    "    rec = history.metrics_distributed[\"recall\"][round_num - 1][1]\n",
    "    f1 = history.metrics_distributed[\"f1_score\"][round_num - 1][1]\n",
    "    print(f\"Round {round_num} => Accuracy: {acc:.2f}%, Precision: {prec:.2f}%, Recall: {rec:.2f}%, F1-score: {f1:.2f}%\")\n",
    "\n",
    "final_acc = history.metrics_distributed[\"accuracy\"][-1][1]\n",
    "final_precision = history.metrics_distributed[\"precision\"][-1][1]\n",
    "final_recall = history.metrics_distributed[\"recall\"][-1][1]\n",
    "final_f1 = history.metrics_distributed[\"f1_score\"][-1][1]\n",
    "print(f\"\\nFinal Metrics â€” Accuracy: {final_acc:.2f}%, Precision: {final_precision:.2f}%, Recall: {final_recall:.2f}%, F1-score: {final_f1:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7125912,
     "sourceId": 11380834,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7125979,
     "sourceId": 11380918,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7126287,
     "sourceId": 11381295,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7234321,
     "sourceId": 11534488,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7234481,
     "sourceId": 11534801,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7234724,
     "sourceId": 11535332,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
